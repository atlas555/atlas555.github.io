<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>文章 on Tech Whims</title>
    <link>https://techwhims.com/cn/blog/</link>
    <description>Recent content in 文章 on Tech Whims</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://techwhims.com/cn/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>我参加了一个写作训练营，《自媒体文章从无到有的过程》学习总结</title>
      <link>https://techwhims.com/cn/2023/04/09/writing-skills-and-books/</link>
      <pubDate>Sun, 09 Apr 2023 14:37:36 +0800</pubDate>
      
      <guid>https://techwhims.com/cn/2023/04/09/writing-skills-and-books/</guid>
      <description>由于好奇心驱使，前段时间参加了粥佐罗老师的写作 7 天训练营， 目的是想了解下自媒体这个行业、以及如何写自媒体文章。
最后一天粥老师进行关于《自媒体文章如何从无到有诞生的》的直播，下面我对这个内容作了些总结（更多内容详见最后的思维导图）。
课程内容核心点：
一篇文章的写作过程，就是一个扩写的过程。将要表达的依据深刻的观点、认知扩写为一篇文章，通过文章说服读者认同、达到共鸣。 写文章是有”套路“的，一篇文章的完成可以总结为 6 个步骤：选题大方向、定具体的选题、确定选题角度、定框架+要点、按照核心点进行扩写、修改打磨完成终稿。 选题方向非常重要，要考虑热度、阅读量、涨粉、优质选题或者爆款、和自己公众号内容长期方向匹配，方向聚焦精力，克制自我欲望 文章输出的灵魂点，一点要有自己独特的视角、见识，通俗来讲就是有可以分享的价值 文章框架结论要根据文章类型来匹配。观点文、情感文、人物稿d等等都有不同架构，合适的架构更能够充分论述核心观点。 写作最重要的是要投入练习，必须在擅长的写作内容上刻意练习（有成长的练习）、合适的投稿方向再加上以团队的指导和激励。 另外通过参加训练营，说一说我对自媒体写作的几个新认知。
自媒体写作者，是一个职业，或者说是一个岗位。职业的话就有职业路径和模式可以参考。类比Java程序员这个职业，根据技术能力有不同的职级。 自媒体写作的目的非常重要。变现、个人IP 不同的定位有不同的发展思路。 自媒体写作文章类型可分为故事人物稿，热点文，观点文，干货文，公文，个人IP商稿等十几个种类，每个方向市场都有很大的需求量。 每个类型文章写作是有”套路“的，按照一套流程下来就可以有一篇文章。 坚持写作需要反馈和刺激。涨粉、阅读量、变现是必不可少的。 另外我对课程内容整理了思维导图，可以下载看大图。 </description>
    </item>
    
    <item>
      <title>读书分享·左晖·做难而正确的事</title>
      <link>https://techwhims.com/cn/2023/04/06/reading/</link>
      <pubDate>Thu, 06 Apr 2023 17:02:36 +0800</pubDate>
      
      <guid>https://techwhims.com/cn/2023/04/06/reading/</guid>
      <description>源于我在高途技术管理会议上的读书分享
做难而正确的事 ·左晖 · 读书分享演讲稿 大家好，给大家分享《左晖·做难而正确的事》这本书，我们组经过内部讨论分享，最后给大家带来 4 个核心点的分享，首先第一核心点是
做难而正确的事情 首先对这这本书核心的核心进行理解，这个是根基，需要多花时间讲一下，其中有两个关键词，第一个什么是难，第二个什么是正确。
我们首先来看关于什么是“难”，左晖对难的理解有两层意思，第一是你要创造价值，如果不创造价值，仅仅获得结果没什么意义，核心是有价值；第二是你在选择的时候，要选择难的路。因为，真正创造价值的事情都难。难而正确的事情，就是你搞不清楚的时候，去选择一条最难的路。
那什么是正确的事情，这个涉及到最底层思维和价值判断。我们尝试通过阅读看看左晖对这个的理解，链家做的无差价、有尊严、真房源、平台化，符合用户和经纪人的价值，这么看都是 100%正确的事情，这些正确的事情是从用户价值角度出发，做了符合用户价值，能让用户体验更好的事情，那如何思考出来的呢？左晖经过很长时间的思考行业和链家，发现这个行业的产品不是房子，而是经纪人的服务能力。他发现在这个行业网络的关键点是是经纪人的服务。所以总结出链家的本质是“以经纪人为消费者提供的品质服务为节点，用信任来连接的关系网络”。做这个事情就是左晖认为有价值的正确的事情。
那为什么要做难而正确的事情呢？容易成功呀。做正确的事肯定是没错的，目标已经在那里了，只是达到目标路径选择的问题？选择难的容易成功，说一下我个人的理解，一是做的人少，困难已经吓退了很多人，第二更重要的是其背后深层次的逻辑，就是要迎难而上。如果有 a 和 b 两条路，各有利弊，你就应该选择短期内更艰难、更痛苦的道路。为什么呢？因为我们在大脑潜意识倾向下，会本能地选择摆脱短期痛苦，这个潜意识倾向非常强，大家回忆下，自己做决策行为的时候是不是深受影响，一般人摆脱不了。
但从很多做成大事的人物传记中经验总结，他们生命中的大部分收获都来自承受短期痛苦而获得的长期回报，所以综合来看主动迎接短期痛苦，压制回避痛苦的潜意识倾向，迎难而上看更容易成功。这些是我个人的理解，如果你们有新的不同理解，可以私下碰撞一下。
大环境和确定性、周期和资本 公司发展受外部经济环境和行业周期影响，经济发展和行业存在周期性的波动，这是客观存在的。在周期中有顶峰，也有谷底，很难去准确的判断周期什么时候是低，什么时候是顶峰，这就像我们投资股票，很难买在最低点，很难卖在最高点。我们知道周期，深受周期影响，但改变不了，这种不确定性时刻存在。
面对不确定性，需要找到自己确定的事情（“正确的事”）。
链家面对大行业中普遍存在的吃差价、假房源的问题不妥协，坚持自己的价值观和原则，做自己确定的事情。推行无差价、真房源的策略，公司经营一度回落到低谷，门店数和经纪人数大量损失，被其他竞争对手反超，不过经过一段时间的坚持运营，相信做的事情是为用户创造真价值，最后数据指标迅速又回来了，形成了正向循环。
面对2021的双减政策，教育行业大地震，我们公司是很难去改变政策，那就需要快速适应变化，我们快速调整业务和组织架构，进行降本增效。
更加坚持地做正确的事情：以 教学产品、教育质量和教学服务 为中心，全面打造 持续、高标准、规模化 育成好老师的组织力，全力实现 伙伴成长和 有效增长
不管外界环境如何变化，我们的初心没变，做教育初心没变。 服务好每一个客户，做难而正确的事情。
可是我们公司在成长中，也走过一些弯路，行业竞争影响的我们。
竞争思维是低效率的 在商业世界里，大多数人在玩零和游戏，你要赢有两个办法，一个是让自己变强，另外就是让别人变弱。关心竞对多了之后，很容易使用第二种方式，还会形成一种心理暗示：“不是我笨，是对手坏”。
就拿咱们公司教育信息流大战举例子，各家使出各种手段，高价投放挤占市场，过渡承诺，攻击对手做的不好的地方吸引用户，最典型的恶性竞争的 case 就是几家教育公司使用同一个老太太做演员，在抖音上投放流量，回头一想，是不可思议。就像去年我花 55 块钱每股买恒大汽车的股票，是一样不可思议的操作。
因为过渡的关注竞争对手，跟风对手，不聚焦，内部组织也出现问题，乱投放、投入大量资金进行广告战，导致我们未能构建好自己的护城河，反而造成大量的亏损
过渡关注竞争对手，会造成认知的偏差
真正强大的团队能够做到三点：承认先进、学习先进、赶超先进 ，我们可以看下现在公司组织内外部的情况，组织内部存在互相看不起的现象，比如产品觉的研发迭代交付慢，质量不好，研发觉的产品设计不好，不满足用户需求等，我记得去年参加第一期美班培训上，产研被业务疯狂 papa 的打脸的惨状；在外部行业上，之前高途看不上作业帮、看不上猿辅导，觉的自己在行业中很厉害，后面也被 papa 的打脸了。承认先进，不自大，才能学习先进，赶超先进。
认识到别人的先进，我们应该如何做呢？ 首先跳出来站在第三方视角看问题，收集信息，挖出真正做的好的项目，从中学习先进方法论，运用到自己的团队中。
好的内容和方法论的落地，离不开一个好的”操作系统“。
何为操作系统 我们先看下左晖是如何理解的操作系统的，“我们想给大家提供这么一个操作系统：我提供一个插槽，只要你愿意插到这个插座里面，按照我的规则走，你的输入项在这里，你就能得到想要的结果。”，贝壳做为系统，解决这个输入输出的问题。这个系统支撑规模化可复制、控制风险，提升整体水平下限，终形成正向循环。
那贝壳又是如何建立这个操作系统的？ 离不开贝壳对行业真问题的分析，对其本质的理解和深度的抽象，构建了贝壳 ACN 网络，提升服务的流通效率，构建这个系统后又持续迭代进化，也就是我们现在看到的样子，他依然在进化。
“任何一个系统都有自己的第一性原理，这是一个根基性的命题或假设“，ACN 操作系统的第一性原理就是上面提到的行业本质（以经纪人为消费者提供的品质服务为节点，用信任来连接的关系网络）。
理解了贝壳ACN系统后，我们在想一下高途应该如何做？我们 2023 年战略落地我觉得就是一套系统，这套系统打造育成好老师的组织力，实现伙伴成长和有效增长，回归到我们产研身上，理解二讲老师服务的底层逻辑，可以建设一套适用于二讲老师的操作系统，帮助提升二讲的服务效率，持续的进化。
one more thing : 好公司的价值观都差不多 好公司的价值观差不多，价值观是驱动力，是决策判断的原则。（客户为先、诚信、协作、担当、创新）
我们有着好的价值观，如果又能打造强大的操作系统，持续为用户创造价值，那还有什么不能做成的呢？（“你是否对某件事情的认知异于行业又坚定的执行着” —《从0到1》）</description>
    </item>
    
    <item>
      <title>Log Structured Merge Tree</title>
      <link>https://techwhims.com/cn/2023/04/06/algorithm/</link>
      <pubDate>Thu, 06 Apr 2023 14:30:25 +0800</pubDate>
      
      <guid>https://techwhims.com/cn/2023/04/06/algorithm/</guid>
      <description>记录于 2023.4.6，源于 hbase 原理的学习。
LSM 的核心思想 LSM树有以下三个重要组成部分：
MemTable
MemTable是在内存中的数据结构，用于保存最近更新的数据，会按照Key有序地组织这些数据，LSM树对于具体如何组织有序地组织数据并没有明确的数据结构定义，例如Hbase使跳跃表来保证内存中key的有序。
因为数据暂时保存在内存中，内存并不是可靠存储，如果断电会丢失数据，因此通常会通过WAL(Write-ahead logging，预写式日志)的方式来保证数据的可靠性。
Immutable MemTable
当 MemTable达到一定大小后，会转化成Immutable MemTable。Immutable MemTable是将转MemTable变为SSTable的一种中间状态。写操作由新的MemTable处理，在转存过程中不阻塞数据更新操作。
SSTable(Sorted String Table)
有序键值对集合，是LSM树组在磁盘中的数据结构。为了加快SSTable的读取，可以通过建立key的索引以及布隆过滤器来加快key的查找。 LSM树的Compact策略 主要介绍两种基本策略：size-tiered和leveled。
重要的概念
读放大:读取数据时实际读取的数据量大于真正的数据量。例如在LSM树中需要先在MemTable查看当前key是否存在，不存在继续从SSTable中寻找。 写放大:写入数据时实际写入的数据量大于真正的数据量。例如在LSM树中写入时可能触发Compact操作，导致实际写入的数据量远大于该key的数据量。 空间放大:数据实际占用的磁盘空间比数据的真正大小更多。上面提到的冗余存储，对于一个key来说，只有最新的那条记录是有效的，而之前的记录都是可以被清理回收的。 size-tiered 策略 size-tiered策略保证每层SSTable的大小相近，同时限制每一层SSTable的数量。如上图，每层限制SSTable为N，当每层SSTable达到N后，则触发Compact操作合并这些SSTable，并将合并后的结果写入到下一层成为一个更大的sstable。 由此可以看出，当层数达到一定数量时，最底层的单个SSTable的大小会变得非常大。并且size-tiered策略会导致空间放大比较严重。即使对于同一层的SSTable，每个key的记录是可能存在多份的，只有当该层的SSTable执行compact操作才会消除这些key的冗余记录。
leveled策略 leveled策略也是采用分层的思想，每一层限制总文件的大小。 但是跟size-tiered策略不同的是，leveled会将每一层切分成多个大小相近的SSTable。这些SSTable是这一层是全局有序的，意味着一个key在每一层至多只有1条记录，不存在冗余记录。 leveled策略相较于size-tiered策略来说，每层内key是不会重复的，即使是最坏的情况，除开最底层外，其余层都是重复key，按照相邻层大小比例为10来算，冗余占比也很小。因此空间放大问题得到缓解。但是写放大问题会更加突出</description>
    </item>
    
    <item>
      <title>数据湖仓一体架构简图</title>
      <link>https://techwhims.com/cn/2023/04/06/datalake/</link>
      <pubDate>Thu, 06 Apr 2023 04:30:25 +0800</pubDate>
      
      <guid>https://techwhims.com/cn/2023/04/06/datalake/</guid>
      <description>记录于 2023.4.6，源于数据湖技术分享。
现在一般有两个方向，湖仓分体是过渡，胡仓一体是最终结果。
我司目前在湖仓分体的方向上演进。即以 hive 为主的 data warehouse 结合 iceberg。</description>
    </item>
    
    <item>
      <title>《Hbase原理和实践》学习摘要</title>
      <link>https://techwhims.com/cn/2023/04/05/data/</link>
      <pubDate>Wed, 05 Apr 2023 21:00:43 +0800</pubDate>
      
      <guid>https://techwhims.com/cn/2023/04/05/data/</guid>
      <description>记录于 2023.02.13
一、基本情况和原理 1、HBase使用现状 （1）使用HBase存储海量数据，服务于各种在线系统以及离线分析系统，业务场景包括订单系统、消息存储系统、用户画像、搜索推荐、安全风控以及物联网时序数据存储等。最近，阿里云、华为云等云提供商先后推出了HBase云服务，为国内更多公司低门槛地使用HBase服务提供了便利。
（2）系统特性：
容量巨大：HBase的单表可以支持千亿行、百万列的数据规模，数据容量可以达到TB甚至PB级别 良好的可扩展性：HBase集群可以非常方便地实现集群容量扩展，主要包括数据存储节点扩展以及读写服务节点扩展 稀疏性：HBase支持大量稀疏存储，即允许大量列值为空，并不占用任何存储空间。 高性能：HBase目前主要擅长于OLTP场景，数据写操作性能强劲，对于随机单点读以及小范围的扫描读，其性能也能够得到保证 多版本：HBase支持多版本特性，即一个KV可以同时保留多个版本 支持过期：HBase支持TTL过期特性，用户只需要设置过期时间，超过TTL的数据就会被自动清理，不需要用户写程序手动删除。 缺陷
HBase本身不支持很复杂的聚合运算（如Join、GroupBy等）。如果业务中需要使用聚合运算，可以在HBase之上架设Phoenix组件或者Spark组件，前者主要应用于小规模聚合的OLTP场景，后者应用于大规模聚合的OLAP场景 HBase本身并没有实现二级索引功能，所以不支持二级索引查找。好在针对HBase实现的第三方二级索引方案非常丰富，比如目前比较普遍的使用Phoenix提供的二级索引功能 HBase原生不支持全局跨行事务，只支持单行事务模型
2、HBase数据模型 称HBase为“sparse, distributed, persistent multidimensional sorted map”，即HBase本质来看是一个Map，从逻辑视图来看，HBase中的数据是以表形式进行组织的，HBase中的表也由行和列构成。从物理视图来看，HBase是一个Map，由键值（KeyValue，KV）构成，不过与普通的Map不同，HBase是一个稀疏的、分布式的、多维排序的Map。
（1）逻辑视图，HBase中的基本概念。
table：表，一个表包含多行数据。 row：行，一行数据包含一个唯一标识rowkey、多个column以及对应的值。在HBase中，一张表中所有row都按照rowkey的字典序由小到大排序。 column：列，与关系型数据库中的列不同，HBase中的column由column family（列簇）以及qualifier（列名）两部分组成，两者中间使用&amp;quot;:&amp;ldquo;相连。比如contents:html，其中contents为列簇，html为列簇下具体的一列。column family在表创建的时候需要指定，用户不能随意增减。一个column family下可以设置任意多个qualifier，因此可以理解为HBase中的列可以动态增加，理论上甚至可以扩展到上百万列。 timestamp：时间戳，每个cell在写入HBase的时候都会默认分配一个时间戳作为该cell的版本，当然，用户也可以在写入的时候自带时间戳。HBase支持多版本特性，即同一rowkey、column下可以有多个value存在，这些value使用timestamp作为版本号，版本越大，表示数据越新。
下图所示，表中主要存储网页信息。 示例表中包含两行数据，两个rowkey分别为com.cnn.www和com.example.www，按照字典序由小到大排列。 每行数据有三个列簇，分别为anchor、contents以及people，其中列簇anchor下有两列，分别为cnnsi.com以及my.look.ca，其他两个列簇都仅有一列。
可以看出，根据行com.cnn.www以及列anchor:cnnsi.com可以定位到数据CNN，对应的时间戳信息是t9。而同一行的另一列contents:html下却有三个版本的数据，版本号分别为t5、t6和t7。
（2）多维稀疏排序Map
HBase中Map的key是一个复合键，由rowkey、column family、qualifier、type以及timestamp组成，value即为cell的值。
{&amp;ldquo;com.cnn.www&amp;rdquo;,&amp;ldquo;anchor&amp;rdquo;,&amp;ldquo;cnnsi.com&amp;rdquo;,&amp;ldquo;put&amp;rdquo;,&amp;ldquo;t9&amp;rdquo;} -&amp;gt; &amp;ldquo;CNN&amp;rdquo; 多维：这个特性比较容易理解。HBase中的Map与普通Map最大的不同在于，key是一个复合数据结构，由多维元素构成，包括rowkey、column family、qualif ier、type以及timestamp。 稀疏：稀疏性是HBase一个突出特点。从图1-3逻辑表中行&amp;quot;com.example.www&amp;quot;可以看出，整整一行仅有一列（people:author）有值，其他列都为空值。在其他数据库中，对于空值的处理一般都会填充null，而对于HBase，空值不需要任何填充。这个特性为什么重要？因为HBase的列在理论上是允许无限扩展的，对于成百万列的表来说，通常都会存在大量的空值，如果使用填充null的策略，势必会造成大量空间的浪费。因此稀疏性是HBase的列可以无限扩展的一个重要条件。 排序：构成HBase的KV在同一个文件中都是有序的，但规则并不是仅仅按照rowkey排序，而是按照KV中的key进行排序——先比较rowkey，rowkey小的排在前面；如果rowkey相同，再比较column，即column family:qualif ier，column小的排在前面；如果column还相同，再比较时间戳timestamp，即版本信息，timestamp大的排在前面。这样的多维元素排序规则对于提升HBase的读取性能至关重要，在后面读取章节会详细分析。 分布式：很容易理解，构成HBase的所有Map并不集中在某台机器上，而是分布在整个集群中。 （3）物理视图
HBase中的数据是按照列簇存储的，即将数据按照列簇分别存储在不同的目录中。
列簇anchor的所有数据存储在一起形成：
（4）行式存储、列式存储、列簇式存储
行式存储：行式存储系统会将一行数据存储在一起，一行数据写完之后再接着写下一行，最典型的如MySQL这类关系型数据库。行式存储在获取一行数据时是很高效的，但是如果某个查询只需要读取表中指定列对应的数据，那么行式存储会先取出一行行数据，再在每一行数据中截取待查找目标列。这种处理方式在查找过程中引入了大量无用列信息，从而导致大量内存占用。
列式存储：列式存储理论上会将一列数据存储在一起，不同列的数据分别集中存储，最典型的如Kudu、Parquet on HDFS等系统（文件格式），列式存储对于只查找某些列数据的请求非常高效，只需要连续读出所有待查目标列，然后遍历处理即可；但是反过来，列式存储对于获取一行的请求就不那么高效了，需要多次IO读多个列数据，最终合并得到一行数据。另外，因为同一列的数据通常都具有相同的数据类型，因此列式存储具有天然的高压缩特性。
列簇式存储：从概念上来说，列簇式存储介于行式存储和列式存储之间，可以通过不同的设计思路在行式存储和列式存储两者之间相互切换
3、HBase体系结构 典型的Master-Slave模型。系统中有一个管理集群的Master节点以及大量实际服务用户读写的RegionServer节点。除此之外，HBase中所有数据最终都存储在HDFS系统中；系统中还有一个ZooKeeper节点，协助Master对集群进行管理
（1）hbase client：HBase客户端（Client）提供了Shell命令行接口、原生Java API编程接口、Thrift/REST API编程接口以及MapReduce编程接口。HBase客户端支持所有常见的DML操作以及DDL操作。HBase客户端访问数据行之前，首先需要通过元数据表定位目标数据所在RegionServer，之后才会发送请求到该RegionServer。同时这些元数据会被缓存在客户端本地，以方便之后的请求访问。如果集群RegionServer发生宕机或者执行了负载均衡等，从而导致数据分片发生迁移，客户端需要重新请求最新的元数据并缓存在本地。
（2）zookeeper：在HBase系统中，ZooKeeper扮演着非常重要的角色。
实现Master高可用：通常情况下系统中只有一个Master工作，一旦Active Master由于异常宕机，ZooKeeper会检测到该宕机事件，并通过一定机制选举出新的Master，保证系统正常运转。 管理系统核心元数据：比如，管理当前系统中正常工作的RegionServer集合，保存系统元数据表hbase:meta所在的RegionServer地址等。 参与RegionServer宕机恢复：ZooKeeper通过心跳可以感知到RegionServer是否宕机，并在宕机后通知Master进行宕机处理。 实现分布式表锁：HBase中对一张表进行各种管理操作（比如alter操作）需要先加表锁，防止其他用户对同一张表进行管理操作，造成表状态不一致。HBase中的表通常都是分布式存储，ZooKeeper可以通过特定机制实现分布式表锁。 （3）Master：Master主要负责HBase系统的各种管理工作：</description>
    </item>
    
    <item>
      <title>数据湖技术比较</title>
      <link>https://techwhims.com/cn/2023/04/05/datalake/</link>
      <pubDate>Wed, 05 Apr 2023 14:30:25 +0800</pubDate>
      
      <guid>https://techwhims.com/cn/2023/04/05/datalake/</guid>
      <description>记录于 2023.4.5，源于数据湖技术分享。</description>
    </item>
    
  </channel>
</rss>
